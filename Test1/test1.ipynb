{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# First try to use the data to train a model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m \u001b[39mimport\u001b[39;00m metrics\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "# First try to use the data to train a model\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.optimizers import SGD\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from the file\n",
    "df = pd.read_csv('myData.csv', header = None)\n",
    "\n",
    "df.head()\n",
    "\n",
    "Dataset = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_X = 3.0;\n",
    "starting_Y = 0.0;\n",
    "arr = np.zeros((1, 0));\n",
    "X = np.empty(2100, dtype = object);\n",
    "Y = np.empty(2100, dtype = object);\n",
    "\n",
    "new_arr = np.empty((2100, 50));\n",
    "\n",
    "for i in range(0, 2099):\n",
    "    if i <= 300:\n",
    "        true_X = starting_X - i*0.01;\n",
    "        true_Y = starting_Y;\n",
    "    elif i <= 600:\n",
    "        true_X = 0.0 + (i-300)*0.01;\n",
    "        true_Y = starting_Y + 0.5;\n",
    "    elif i <= 900:\n",
    "        true_X = starting_X - (i-600)*0.01;\n",
    "        true_Y = starting_Y + 1.0;\n",
    "    elif i <= 1200:\n",
    "        true_X = 0.0 + (i-900)*0.01;\n",
    "        true_Y = starting_Y + 1.5;\n",
    "    elif i <= 1500:\n",
    "        true_X = starting_X - (i-1200)*0.01;\n",
    "        true_Y = starting_Y + 2.0;\n",
    "    elif i <= 1800:\n",
    "        true_X = 0.0 + (i-1500)*0.01;\n",
    "        true_Y = starting_Y + 2.5;\n",
    "    elif i <= 2100:\n",
    "        true_X = starting_X - (i-1800)*0.01;\n",
    "        true_Y = starting_Y + 3.0;\n",
    "        \n",
    "    new_arr[i,:] = np.array([true_X, true_Y, Dataset[i, 0], Dataset[i, 1], Dataset[i, 2], Dataset[i, 3], Dataset[i, 4], Dataset[i, 5], Dataset[i, 6], Dataset[i, 7], Dataset[i, 8], Dataset[i, 9], Dataset[i, 10], Dataset[i, 11], Dataset[i, 12], Dataset[i, 13], Dataset[i, 14], Dataset[i, 15], Dataset[i, 16], Dataset[i, 17], Dataset[i, 18], Dataset[i, 19], Dataset[i, 20], Dataset[i, 21], Dataset[i, 22], Dataset[i, 23], Dataset[i, 24], Dataset[i, 25], Dataset[i, 26], Dataset[i, 27], Dataset[i, 28], Dataset[i, 29], Dataset[i, 30], Dataset[i, 31], Dataset[i, 32], Dataset[i, 33], Dataset[i, 34], Dataset[i, 35], Dataset[i, 36], Dataset[i, 37], Dataset[i, 38], Dataset[i, 39], Dataset[i, 40], Dataset[i, 41], Dataset[i, 42], Dataset[i, 43], Dataset[i, 44], Dataset[i, 45], Dataset[i, 46], Dataset[i, 47]])\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "# print(arr)\n",
    "# print (df)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning - Prepare the data\n",
    "\n",
    "X = new_arr[:, 2:50];\n",
    "Y = new_arr[:, 0:2];\n",
    "\n",
    "# print(X[0,:])\n",
    "# print(Y)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.20, random_state = 42)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_11 (Dense)            (None, 1536)              75264     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1536)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 768)               1180416   \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 768)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 384)               295296    \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 192)               73920     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 96)                18528     \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 48)                4656      \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 24)                1176      \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 12)                300       \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 4)                 36        \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 2)                 10        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,649,706\n",
      "Trainable params: 1,649,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Machine Learning - Build the model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(1536, activation = 'relu', input_shape = (48,))) # input layerr\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(768, activation = 'relu')) # input layerr\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(384, activation = 'relu')) # input layerr\n",
    "model.add(Dense(192, activation = 'relu')) # input layerr\n",
    "model.add(Dense(96, activation = 'relu')) # input layer\n",
    "model.add(Dense(48, activation = 'relu')) # input layer\n",
    "model.add(Dense(24, activation = 'relu'))\n",
    "model.add(Dense(12, activation = 'relu'))\n",
    "model.add(Dense(8, activation = 'relu'))\n",
    "model.add(Dense(4, activation = 'relu'))\n",
    "model.add(Dense(2, activation = 'linear'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# model.compile(loss = 'SparseCategori', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.compile(loss = 'mse', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "80/80 [==============================] - 2s 11ms/step - loss: 1.6931 - accuracy: 0.5000 - val_loss: 1.0988 - val_accuracy: 0.4833\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 1.0166 - accuracy: 0.5018 - val_loss: 0.9255 - val_accuracy: 0.5000\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.8444 - accuracy: 0.5149 - val_loss: 0.7554 - val_accuracy: 0.5214\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.7253 - accuracy: 0.5393 - val_loss: 0.7235 - val_accuracy: 0.5881\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.6719 - accuracy: 0.5673 - val_loss: 0.6404 - val_accuracy: 0.6024\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.6289 - accuracy: 0.6315 - val_loss: 0.6371 - val_accuracy: 0.6905\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.6248 - accuracy: 0.6625 - val_loss: 0.6815 - val_accuracy: 0.6452\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.6286 - accuracy: 0.6798 - val_loss: 0.6213 - val_accuracy: 0.6833\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.6047 - accuracy: 0.6863 - val_loss: 0.6223 - val_accuracy: 0.6786\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.6126 - accuracy: 0.6804 - val_loss: 0.6114 - val_accuracy: 0.7190\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5971 - accuracy: 0.6798 - val_loss: 0.6213 - val_accuracy: 0.7214\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.6064 - accuracy: 0.6815 - val_loss: 0.6014 - val_accuracy: 0.7262\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5941 - accuracy: 0.6851 - val_loss: 0.6021 - val_accuracy: 0.6548\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5936 - accuracy: 0.6839 - val_loss: 0.5963 - val_accuracy: 0.6905\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5813 - accuracy: 0.6845 - val_loss: 0.5925 - val_accuracy: 0.6833\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5829 - accuracy: 0.6857 - val_loss: 0.5897 - val_accuracy: 0.6952\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5834 - accuracy: 0.6839 - val_loss: 0.6038 - val_accuracy: 0.6810\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5826 - accuracy: 0.6869 - val_loss: 0.5971 - val_accuracy: 0.6905\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5715 - accuracy: 0.6893 - val_loss: 0.5867 - val_accuracy: 0.6786\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5820 - accuracy: 0.6881 - val_loss: 0.5885 - val_accuracy: 0.7095\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5701 - accuracy: 0.6762 - val_loss: 0.5787 - val_accuracy: 0.7167\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5733 - accuracy: 0.6905 - val_loss: 0.5876 - val_accuracy: 0.7214\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5764 - accuracy: 0.6905 - val_loss: 0.5921 - val_accuracy: 0.6929\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5670 - accuracy: 0.6905 - val_loss: 0.5827 - val_accuracy: 0.6952\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5637 - accuracy: 0.6935 - val_loss: 0.5758 - val_accuracy: 0.6810\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5627 - accuracy: 0.6869 - val_loss: 0.5912 - val_accuracy: 0.7000\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5632 - accuracy: 0.6976 - val_loss: 0.5744 - val_accuracy: 0.7167\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5704 - accuracy: 0.6964 - val_loss: 0.5742 - val_accuracy: 0.7024\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5570 - accuracy: 0.6917 - val_loss: 0.5702 - val_accuracy: 0.7167\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5600 - accuracy: 0.6964 - val_loss: 0.5698 - val_accuracy: 0.7238\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5597 - accuracy: 0.6994 - val_loss: 0.5711 - val_accuracy: 0.7071\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5551 - accuracy: 0.7018 - val_loss: 0.5608 - val_accuracy: 0.7238\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5566 - accuracy: 0.7018 - val_loss: 0.5629 - val_accuracy: 0.7310\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5646 - accuracy: 0.7077 - val_loss: 0.5613 - val_accuracy: 0.7024\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5548 - accuracy: 0.7071 - val_loss: 0.5715 - val_accuracy: 0.7381\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5486 - accuracy: 0.7060 - val_loss: 0.5590 - val_accuracy: 0.6881\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5483 - accuracy: 0.7054 - val_loss: 0.5655 - val_accuracy: 0.7095\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5458 - accuracy: 0.7042 - val_loss: 0.5555 - val_accuracy: 0.7286\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5433 - accuracy: 0.7101 - val_loss: 0.5472 - val_accuracy: 0.7095\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5495 - accuracy: 0.7024 - val_loss: 0.5626 - val_accuracy: 0.7167\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5355 - accuracy: 0.7155 - val_loss: 0.5501 - val_accuracy: 0.7119\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5367 - accuracy: 0.7161 - val_loss: 0.5479 - val_accuracy: 0.7119\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5368 - accuracy: 0.7119 - val_loss: 0.5658 - val_accuracy: 0.7357\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5376 - accuracy: 0.7071 - val_loss: 0.5419 - val_accuracy: 0.7071\n",
      "Epoch 45/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5311 - accuracy: 0.7113 - val_loss: 0.5366 - val_accuracy: 0.7167\n",
      "Epoch 46/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5277 - accuracy: 0.7095 - val_loss: 0.5415 - val_accuracy: 0.7190\n",
      "Epoch 47/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5336 - accuracy: 0.7107 - val_loss: 0.5426 - val_accuracy: 0.7214\n",
      "Epoch 48/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5335 - accuracy: 0.7125 - val_loss: 0.5689 - val_accuracy: 0.7095\n",
      "Epoch 49/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5327 - accuracy: 0.7173 - val_loss: 0.5271 - val_accuracy: 0.6952\n",
      "Epoch 50/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5198 - accuracy: 0.7149 - val_loss: 0.5249 - val_accuracy: 0.7310\n",
      "Epoch 51/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5248 - accuracy: 0.7167 - val_loss: 0.5411 - val_accuracy: 0.7238\n",
      "Epoch 52/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5224 - accuracy: 0.7173 - val_loss: 0.5227 - val_accuracy: 0.7214\n",
      "Epoch 53/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5199 - accuracy: 0.7167 - val_loss: 0.5213 - val_accuracy: 0.7381\n",
      "Epoch 54/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5179 - accuracy: 0.7149 - val_loss: 0.5184 - val_accuracy: 0.7214\n",
      "Epoch 55/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5188 - accuracy: 0.7149 - val_loss: 0.5201 - val_accuracy: 0.7405\n",
      "Epoch 56/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5114 - accuracy: 0.7167 - val_loss: 0.5125 - val_accuracy: 0.7238\n",
      "Epoch 57/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5115 - accuracy: 0.7256 - val_loss: 0.5121 - val_accuracy: 0.7310\n",
      "Epoch 58/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5151 - accuracy: 0.7214 - val_loss: 0.5157 - val_accuracy: 0.7214\n",
      "Epoch 59/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5123 - accuracy: 0.7256 - val_loss: 0.5235 - val_accuracy: 0.7429\n",
      "Epoch 60/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5106 - accuracy: 0.7185 - val_loss: 0.5062 - val_accuracy: 0.7286\n",
      "Epoch 61/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5073 - accuracy: 0.7226 - val_loss: 0.5049 - val_accuracy: 0.7381\n",
      "Epoch 62/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5056 - accuracy: 0.7321 - val_loss: 0.5045 - val_accuracy: 0.7333\n",
      "Epoch 63/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4987 - accuracy: 0.7232 - val_loss: 0.5193 - val_accuracy: 0.7500\n",
      "Epoch 64/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5068 - accuracy: 0.7262 - val_loss: 0.4978 - val_accuracy: 0.7381\n",
      "Epoch 65/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4978 - accuracy: 0.7238 - val_loss: 0.5006 - val_accuracy: 0.7167\n",
      "Epoch 66/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4946 - accuracy: 0.7238 - val_loss: 0.4986 - val_accuracy: 0.7452\n",
      "Epoch 67/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4988 - accuracy: 0.7185 - val_loss: 0.5172 - val_accuracy: 0.7167\n",
      "Epoch 68/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5036 - accuracy: 0.7232 - val_loss: 0.4980 - val_accuracy: 0.7143\n",
      "Epoch 69/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5057 - accuracy: 0.7250 - val_loss: 0.5027 - val_accuracy: 0.7405\n",
      "Epoch 70/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4938 - accuracy: 0.7256 - val_loss: 0.4963 - val_accuracy: 0.7429\n",
      "Epoch 71/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4934 - accuracy: 0.7262 - val_loss: 0.4866 - val_accuracy: 0.7238\n",
      "Epoch 72/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4956 - accuracy: 0.7304 - val_loss: 0.4888 - val_accuracy: 0.7524\n",
      "Epoch 73/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4868 - accuracy: 0.7339 - val_loss: 0.4846 - val_accuracy: 0.7476\n",
      "Epoch 74/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4872 - accuracy: 0.7298 - val_loss: 0.4835 - val_accuracy: 0.7310\n",
      "Epoch 75/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4916 - accuracy: 0.7357 - val_loss: 0.4876 - val_accuracy: 0.7262\n",
      "Epoch 76/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4927 - accuracy: 0.7321 - val_loss: 0.4799 - val_accuracy: 0.7310\n",
      "Epoch 77/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4838 - accuracy: 0.7304 - val_loss: 0.5094 - val_accuracy: 0.7262\n",
      "Epoch 78/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4940 - accuracy: 0.7363 - val_loss: 0.4834 - val_accuracy: 0.7119\n",
      "Epoch 79/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4895 - accuracy: 0.7286 - val_loss: 0.4772 - val_accuracy: 0.7167\n",
      "Epoch 80/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4805 - accuracy: 0.7292 - val_loss: 0.4769 - val_accuracy: 0.7286\n",
      "Epoch 81/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4791 - accuracy: 0.7268 - val_loss: 0.4745 - val_accuracy: 0.7405\n",
      "Epoch 82/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4828 - accuracy: 0.7351 - val_loss: 0.4802 - val_accuracy: 0.7262\n",
      "Epoch 83/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4835 - accuracy: 0.7345 - val_loss: 0.4883 - val_accuracy: 0.7619\n",
      "Epoch 84/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4808 - accuracy: 0.7321 - val_loss: 0.4723 - val_accuracy: 0.7500\n",
      "Epoch 85/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4734 - accuracy: 0.7286 - val_loss: 0.4661 - val_accuracy: 0.7524\n",
      "Epoch 86/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4752 - accuracy: 0.7393 - val_loss: 0.4634 - val_accuracy: 0.7452\n",
      "Epoch 87/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4716 - accuracy: 0.7351 - val_loss: 0.4589 - val_accuracy: 0.7429\n",
      "Epoch 88/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4678 - accuracy: 0.7417 - val_loss: 0.4595 - val_accuracy: 0.7595\n",
      "Epoch 89/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4665 - accuracy: 0.7464 - val_loss: 0.4646 - val_accuracy: 0.7571\n",
      "Epoch 90/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4702 - accuracy: 0.7458 - val_loss: 0.4587 - val_accuracy: 0.7571\n",
      "Epoch 91/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4643 - accuracy: 0.7458 - val_loss: 0.4601 - val_accuracy: 0.7405\n",
      "Epoch 92/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4610 - accuracy: 0.7619 - val_loss: 0.4533 - val_accuracy: 0.7429\n",
      "Epoch 93/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4623 - accuracy: 0.7548 - val_loss: 0.4741 - val_accuracy: 0.7310\n",
      "Epoch 94/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4641 - accuracy: 0.7631 - val_loss: 0.4579 - val_accuracy: 0.7310\n",
      "Epoch 95/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4600 - accuracy: 0.7583 - val_loss: 0.4543 - val_accuracy: 0.7571\n",
      "Epoch 96/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4640 - accuracy: 0.7482 - val_loss: 0.4478 - val_accuracy: 0.7571\n",
      "Epoch 97/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4559 - accuracy: 0.7560 - val_loss: 0.4453 - val_accuracy: 0.7571\n",
      "Epoch 98/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4564 - accuracy: 0.7607 - val_loss: 0.4536 - val_accuracy: 0.7619\n",
      "Epoch 99/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4553 - accuracy: 0.7554 - val_loss: 0.4434 - val_accuracy: 0.7643\n",
      "Epoch 100/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4550 - accuracy: 0.7577 - val_loss: 0.4440 - val_accuracy: 0.7548\n",
      "Epoch 101/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4514 - accuracy: 0.7643 - val_loss: 0.4465 - val_accuracy: 0.7595\n",
      "Epoch 102/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4553 - accuracy: 0.7643 - val_loss: 0.4428 - val_accuracy: 0.7619\n",
      "Epoch 103/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4514 - accuracy: 0.7667 - val_loss: 0.4460 - val_accuracy: 0.7690\n",
      "Epoch 104/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4516 - accuracy: 0.7595 - val_loss: 0.4476 - val_accuracy: 0.7643\n",
      "Epoch 105/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4494 - accuracy: 0.7667 - val_loss: 0.4457 - val_accuracy: 0.7667\n",
      "Epoch 106/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4535 - accuracy: 0.7619 - val_loss: 0.4374 - val_accuracy: 0.7571\n",
      "Epoch 107/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4473 - accuracy: 0.7601 - val_loss: 0.4352 - val_accuracy: 0.7619\n",
      "Epoch 108/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4470 - accuracy: 0.7655 - val_loss: 0.4330 - val_accuracy: 0.7667\n",
      "Epoch 109/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4489 - accuracy: 0.7714 - val_loss: 0.4458 - val_accuracy: 0.7643\n",
      "Epoch 110/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4464 - accuracy: 0.7685 - val_loss: 0.4328 - val_accuracy: 0.7690\n",
      "Epoch 111/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4461 - accuracy: 0.7762 - val_loss: 0.4318 - val_accuracy: 0.7738\n",
      "Epoch 112/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4427 - accuracy: 0.7738 - val_loss: 0.4297 - val_accuracy: 0.7643\n",
      "Epoch 113/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4449 - accuracy: 0.7726 - val_loss: 0.4304 - val_accuracy: 0.7524\n",
      "Epoch 114/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4442 - accuracy: 0.7726 - val_loss: 0.4317 - val_accuracy: 0.7881\n",
      "Epoch 115/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4479 - accuracy: 0.7804 - val_loss: 0.4291 - val_accuracy: 0.7786\n",
      "Epoch 116/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4410 - accuracy: 0.7810 - val_loss: 0.4377 - val_accuracy: 0.7643\n",
      "Epoch 117/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4449 - accuracy: 0.7774 - val_loss: 0.4259 - val_accuracy: 0.7667\n",
      "Epoch 118/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4441 - accuracy: 0.7726 - val_loss: 0.4257 - val_accuracy: 0.7619\n",
      "Epoch 119/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4425 - accuracy: 0.7732 - val_loss: 0.4235 - val_accuracy: 0.7643\n",
      "Epoch 120/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4397 - accuracy: 0.7857 - val_loss: 0.4213 - val_accuracy: 0.7881\n",
      "Epoch 121/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4388 - accuracy: 0.7821 - val_loss: 0.4229 - val_accuracy: 0.7619\n",
      "Epoch 122/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4381 - accuracy: 0.7845 - val_loss: 0.4195 - val_accuracy: 0.7952\n",
      "Epoch 123/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4407 - accuracy: 0.7786 - val_loss: 0.4389 - val_accuracy: 0.7643\n",
      "Epoch 124/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4411 - accuracy: 0.7875 - val_loss: 0.4217 - val_accuracy: 0.7714\n",
      "Epoch 125/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4397 - accuracy: 0.7815 - val_loss: 0.4222 - val_accuracy: 0.7857\n",
      "Epoch 126/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4368 - accuracy: 0.7911 - val_loss: 0.4285 - val_accuracy: 0.7643\n",
      "Epoch 127/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4419 - accuracy: 0.7833 - val_loss: 0.4238 - val_accuracy: 0.7786\n",
      "Epoch 128/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4380 - accuracy: 0.7905 - val_loss: 0.4159 - val_accuracy: 0.7786\n",
      "Epoch 129/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4333 - accuracy: 0.7893 - val_loss: 0.4191 - val_accuracy: 0.7881\n",
      "Epoch 130/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4400 - accuracy: 0.7893 - val_loss: 0.4204 - val_accuracy: 0.7905\n",
      "Epoch 131/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4363 - accuracy: 0.7929 - val_loss: 0.4156 - val_accuracy: 0.8000\n",
      "Epoch 132/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4327 - accuracy: 0.7952 - val_loss: 0.4136 - val_accuracy: 0.7833\n",
      "Epoch 133/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4356 - accuracy: 0.7935 - val_loss: 0.4171 - val_accuracy: 0.7929\n",
      "Epoch 134/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4331 - accuracy: 0.8000 - val_loss: 0.4136 - val_accuracy: 0.7952\n",
      "Epoch 135/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4341 - accuracy: 0.7952 - val_loss: 0.4122 - val_accuracy: 0.7881\n",
      "Epoch 136/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4336 - accuracy: 0.8018 - val_loss: 0.4104 - val_accuracy: 0.7881\n",
      "Epoch 137/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4325 - accuracy: 0.7958 - val_loss: 0.4105 - val_accuracy: 0.7952\n",
      "Epoch 138/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4310 - accuracy: 0.7994 - val_loss: 0.4102 - val_accuracy: 0.7929\n",
      "Epoch 139/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4311 - accuracy: 0.7964 - val_loss: 0.4115 - val_accuracy: 0.8024\n",
      "Epoch 140/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4298 - accuracy: 0.7952 - val_loss: 0.4109 - val_accuracy: 0.7905\n",
      "Epoch 141/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4295 - accuracy: 0.7988 - val_loss: 0.4065 - val_accuracy: 0.8024\n",
      "Epoch 142/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4322 - accuracy: 0.8071 - val_loss: 0.4089 - val_accuracy: 0.7952\n",
      "Epoch 143/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4279 - accuracy: 0.7976 - val_loss: 0.4079 - val_accuracy: 0.7905\n",
      "Epoch 144/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4337 - accuracy: 0.7988 - val_loss: 0.4064 - val_accuracy: 0.7976\n",
      "Epoch 145/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4279 - accuracy: 0.8018 - val_loss: 0.4199 - val_accuracy: 0.8048\n",
      "Epoch 146/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4271 - accuracy: 0.8024 - val_loss: 0.4042 - val_accuracy: 0.8024\n",
      "Epoch 147/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4284 - accuracy: 0.8018 - val_loss: 0.4037 - val_accuracy: 0.8000\n",
      "Epoch 148/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4338 - accuracy: 0.8000 - val_loss: 0.4062 - val_accuracy: 0.7857\n",
      "Epoch 149/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4254 - accuracy: 0.8036 - val_loss: 0.4024 - val_accuracy: 0.7976\n",
      "Epoch 150/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4213 - accuracy: 0.8024 - val_loss: 0.4017 - val_accuracy: 0.7881\n",
      "Epoch 151/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4193 - accuracy: 0.8012 - val_loss: 0.3999 - val_accuracy: 0.8024\n",
      "Epoch 152/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4198 - accuracy: 0.8006 - val_loss: 0.4041 - val_accuracy: 0.8048\n",
      "Epoch 153/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4204 - accuracy: 0.8036 - val_loss: 0.4013 - val_accuracy: 0.7976\n",
      "Epoch 154/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4226 - accuracy: 0.8101 - val_loss: 0.4063 - val_accuracy: 0.8000\n",
      "Epoch 155/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4186 - accuracy: 0.8048 - val_loss: 0.3984 - val_accuracy: 0.8000\n",
      "Epoch 156/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4177 - accuracy: 0.8071 - val_loss: 0.3983 - val_accuracy: 0.8048\n",
      "Epoch 157/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4178 - accuracy: 0.8060 - val_loss: 0.4014 - val_accuracy: 0.7952\n",
      "Epoch 158/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4193 - accuracy: 0.8054 - val_loss: 0.4058 - val_accuracy: 0.7976\n",
      "Epoch 159/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4230 - accuracy: 0.8048 - val_loss: 0.4013 - val_accuracy: 0.8024\n",
      "Epoch 160/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4181 - accuracy: 0.7994 - val_loss: 0.4003 - val_accuracy: 0.8119\n",
      "Epoch 161/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4177 - accuracy: 0.8030 - val_loss: 0.3967 - val_accuracy: 0.8119\n",
      "Epoch 162/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4156 - accuracy: 0.8119 - val_loss: 0.4009 - val_accuracy: 0.8095\n",
      "Epoch 163/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4175 - accuracy: 0.8101 - val_loss: 0.3986 - val_accuracy: 0.8024\n",
      "Epoch 164/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4169 - accuracy: 0.8048 - val_loss: 0.3967 - val_accuracy: 0.8000\n",
      "Epoch 165/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4153 - accuracy: 0.8089 - val_loss: 0.4002 - val_accuracy: 0.8095\n",
      "Epoch 166/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4169 - accuracy: 0.8101 - val_loss: 0.3974 - val_accuracy: 0.8286\n",
      "Epoch 167/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4172 - accuracy: 0.8054 - val_loss: 0.3959 - val_accuracy: 0.8000\n",
      "Epoch 168/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4162 - accuracy: 0.8149 - val_loss: 0.3932 - val_accuracy: 0.8119\n",
      "Epoch 169/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4175 - accuracy: 0.8036 - val_loss: 0.3938 - val_accuracy: 0.8048\n",
      "Epoch 170/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4146 - accuracy: 0.8089 - val_loss: 0.3940 - val_accuracy: 0.8143\n",
      "Epoch 171/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4148 - accuracy: 0.8125 - val_loss: 0.3944 - val_accuracy: 0.8143\n",
      "Epoch 172/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4149 - accuracy: 0.8143 - val_loss: 0.3962 - val_accuracy: 0.7952\n",
      "Epoch 173/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4153 - accuracy: 0.8071 - val_loss: 0.3936 - val_accuracy: 0.8095\n",
      "Epoch 174/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4145 - accuracy: 0.8119 - val_loss: 0.3955 - val_accuracy: 0.8048\n",
      "Epoch 175/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4157 - accuracy: 0.8107 - val_loss: 0.3955 - val_accuracy: 0.7976\n",
      "Epoch 176/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4167 - accuracy: 0.8107 - val_loss: 0.3968 - val_accuracy: 0.8095\n",
      "Epoch 177/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4148 - accuracy: 0.8143 - val_loss: 0.3942 - val_accuracy: 0.8071\n",
      "Epoch 178/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4160 - accuracy: 0.8054 - val_loss: 0.3960 - val_accuracy: 0.8143\n",
      "Epoch 179/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4201 - accuracy: 0.8095 - val_loss: 0.4638 - val_accuracy: 0.7833\n",
      "Epoch 180/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4195 - accuracy: 0.8113 - val_loss: 0.3951 - val_accuracy: 0.8048\n",
      "Epoch 181/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4148 - accuracy: 0.8137 - val_loss: 0.3927 - val_accuracy: 0.8167\n",
      "Epoch 182/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4148 - accuracy: 0.8161 - val_loss: 0.3970 - val_accuracy: 0.8119\n",
      "Epoch 183/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4151 - accuracy: 0.8113 - val_loss: 0.3907 - val_accuracy: 0.8143\n",
      "Epoch 184/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4152 - accuracy: 0.8208 - val_loss: 0.3933 - val_accuracy: 0.8119\n",
      "Epoch 185/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4143 - accuracy: 0.8113 - val_loss: 0.3916 - val_accuracy: 0.8071\n",
      "Epoch 186/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4149 - accuracy: 0.8137 - val_loss: 0.3920 - val_accuracy: 0.8167\n",
      "Epoch 187/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4141 - accuracy: 0.8107 - val_loss: 0.3907 - val_accuracy: 0.8119\n",
      "Epoch 188/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4128 - accuracy: 0.8155 - val_loss: 0.3909 - val_accuracy: 0.8071\n",
      "Epoch 189/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4117 - accuracy: 0.8143 - val_loss: 0.3894 - val_accuracy: 0.8167\n",
      "Epoch 190/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4124 - accuracy: 0.8190 - val_loss: 0.3920 - val_accuracy: 0.8071\n",
      "Epoch 191/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4143 - accuracy: 0.8185 - val_loss: 0.3910 - val_accuracy: 0.8119\n",
      "Epoch 192/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4131 - accuracy: 0.8179 - val_loss: 0.3915 - val_accuracy: 0.8024\n",
      "Epoch 193/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4123 - accuracy: 0.8155 - val_loss: 0.3911 - val_accuracy: 0.8119\n",
      "Epoch 194/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4112 - accuracy: 0.8214 - val_loss: 0.3880 - val_accuracy: 0.8190\n",
      "Epoch 195/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4136 - accuracy: 0.8190 - val_loss: 0.3852 - val_accuracy: 0.8095\n",
      "Epoch 196/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3919 - accuracy: 0.8220 - val_loss: 0.3689 - val_accuracy: 0.8024\n",
      "Epoch 197/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3821 - accuracy: 0.8179 - val_loss: 0.3437 - val_accuracy: 0.8238\n",
      "Epoch 198/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3705 - accuracy: 0.8262 - val_loss: 0.3431 - val_accuracy: 0.8190\n",
      "Epoch 199/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3680 - accuracy: 0.8202 - val_loss: 0.3414 - val_accuracy: 0.8286\n",
      "Epoch 200/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3667 - accuracy: 0.8292 - val_loss: 0.3418 - val_accuracy: 0.8167\n",
      "Epoch 201/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3654 - accuracy: 0.8232 - val_loss: 0.3396 - val_accuracy: 0.8190\n",
      "Epoch 202/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3628 - accuracy: 0.8262 - val_loss: 0.3364 - val_accuracy: 0.8238\n",
      "Epoch 203/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3637 - accuracy: 0.8262 - val_loss: 0.3382 - val_accuracy: 0.8119\n",
      "Epoch 204/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3627 - accuracy: 0.8381 - val_loss: 0.3356 - val_accuracy: 0.8214\n",
      "Epoch 205/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3610 - accuracy: 0.8274 - val_loss: 0.3336 - val_accuracy: 0.8262\n",
      "Epoch 206/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3603 - accuracy: 0.8327 - val_loss: 0.3331 - val_accuracy: 0.8238\n",
      "Epoch 207/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3556 - accuracy: 0.8321 - val_loss: 0.3238 - val_accuracy: 0.8262\n",
      "Epoch 208/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3553 - accuracy: 0.8292 - val_loss: 0.3336 - val_accuracy: 0.8381\n",
      "Epoch 209/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3467 - accuracy: 0.8304 - val_loss: 0.3173 - val_accuracy: 0.8452\n",
      "Epoch 210/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3431 - accuracy: 0.8345 - val_loss: 0.3185 - val_accuracy: 0.8405\n",
      "Epoch 211/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3398 - accuracy: 0.8357 - val_loss: 0.3137 - val_accuracy: 0.8429\n",
      "Epoch 212/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3370 - accuracy: 0.8357 - val_loss: 0.3148 - val_accuracy: 0.8381\n",
      "Epoch 213/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3375 - accuracy: 0.8351 - val_loss: 0.3132 - val_accuracy: 0.8357\n",
      "Epoch 214/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3367 - accuracy: 0.8280 - val_loss: 0.3160 - val_accuracy: 0.8190\n",
      "Epoch 215/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3353 - accuracy: 0.8357 - val_loss: 0.3106 - val_accuracy: 0.8405\n",
      "Epoch 216/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3342 - accuracy: 0.8333 - val_loss: 0.3114 - val_accuracy: 0.8310\n",
      "Epoch 217/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3305 - accuracy: 0.8345 - val_loss: 0.3083 - val_accuracy: 0.8310\n",
      "Epoch 218/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3319 - accuracy: 0.8321 - val_loss: 0.3095 - val_accuracy: 0.8381\n",
      "Epoch 219/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3310 - accuracy: 0.8327 - val_loss: 0.3061 - val_accuracy: 0.8333\n",
      "Epoch 220/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3300 - accuracy: 0.8357 - val_loss: 0.3081 - val_accuracy: 0.8333\n",
      "Epoch 221/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3302 - accuracy: 0.8363 - val_loss: 0.3121 - val_accuracy: 0.8262\n",
      "Epoch 222/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3300 - accuracy: 0.8310 - val_loss: 0.3070 - val_accuracy: 0.8357\n",
      "Epoch 223/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3282 - accuracy: 0.8411 - val_loss: 0.3069 - val_accuracy: 0.8405\n",
      "Epoch 224/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3306 - accuracy: 0.8375 - val_loss: 0.3118 - val_accuracy: 0.8357\n",
      "Epoch 225/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3279 - accuracy: 0.8375 - val_loss: 0.3077 - val_accuracy: 0.8357\n",
      "Epoch 226/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3285 - accuracy: 0.8423 - val_loss: 0.3080 - val_accuracy: 0.8476\n",
      "Epoch 227/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3271 - accuracy: 0.8446 - val_loss: 0.3072 - val_accuracy: 0.8405\n",
      "Epoch 228/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3270 - accuracy: 0.8351 - val_loss: 0.3059 - val_accuracy: 0.8357\n",
      "Epoch 229/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3275 - accuracy: 0.8327 - val_loss: 0.3046 - val_accuracy: 0.8310\n",
      "Epoch 230/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3286 - accuracy: 0.8298 - val_loss: 0.3141 - val_accuracy: 0.8381\n",
      "Epoch 231/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3282 - accuracy: 0.8327 - val_loss: 0.3052 - val_accuracy: 0.8310\n",
      "Epoch 232/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3260 - accuracy: 0.8333 - val_loss: 0.3064 - val_accuracy: 0.8381\n",
      "Epoch 233/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3255 - accuracy: 0.8381 - val_loss: 0.3059 - val_accuracy: 0.8333\n",
      "Epoch 234/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3247 - accuracy: 0.8399 - val_loss: 0.3030 - val_accuracy: 0.8429\n",
      "Epoch 235/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3254 - accuracy: 0.8393 - val_loss: 0.3057 - val_accuracy: 0.8405\n",
      "Epoch 236/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3265 - accuracy: 0.8339 - val_loss: 0.3061 - val_accuracy: 0.8238\n",
      "Epoch 237/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3256 - accuracy: 0.8375 - val_loss: 0.3054 - val_accuracy: 0.8381\n",
      "Epoch 238/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3261 - accuracy: 0.8363 - val_loss: 0.3078 - val_accuracy: 0.8381\n",
      "Epoch 239/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3261 - accuracy: 0.8345 - val_loss: 0.3064 - val_accuracy: 0.8333\n",
      "Epoch 240/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3254 - accuracy: 0.8435 - val_loss: 0.3052 - val_accuracy: 0.8429\n",
      "Epoch 241/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3257 - accuracy: 0.8393 - val_loss: 0.3050 - val_accuracy: 0.8310\n",
      "Epoch 242/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3244 - accuracy: 0.8417 - val_loss: 0.3070 - val_accuracy: 0.8333\n",
      "Epoch 243/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3287 - accuracy: 0.8405 - val_loss: 0.3095 - val_accuracy: 0.8381\n",
      "Epoch 244/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3264 - accuracy: 0.8339 - val_loss: 0.3046 - val_accuracy: 0.8429\n",
      "Epoch 245/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3328 - accuracy: 0.8333 - val_loss: 0.3055 - val_accuracy: 0.8381\n",
      "Epoch 246/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3275 - accuracy: 0.8280 - val_loss: 0.3100 - val_accuracy: 0.8333\n",
      "Epoch 247/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3271 - accuracy: 0.8351 - val_loss: 0.3115 - val_accuracy: 0.8238\n",
      "Epoch 248/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3256 - accuracy: 0.8369 - val_loss: 0.3086 - val_accuracy: 0.8333\n",
      "Epoch 249/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3262 - accuracy: 0.8369 - val_loss: 0.3061 - val_accuracy: 0.8381\n",
      "Epoch 250/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3259 - accuracy: 0.8345 - val_loss: 0.3038 - val_accuracy: 0.8429\n",
      "Epoch 251/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3263 - accuracy: 0.8357 - val_loss: 0.3089 - val_accuracy: 0.8286\n",
      "Epoch 252/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3258 - accuracy: 0.8440 - val_loss: 0.3035 - val_accuracy: 0.8405\n",
      "Epoch 253/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3244 - accuracy: 0.8381 - val_loss: 0.3053 - val_accuracy: 0.8381\n",
      "Epoch 254/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3263 - accuracy: 0.8339 - val_loss: 0.3056 - val_accuracy: 0.8333\n",
      "Epoch 255/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3242 - accuracy: 0.8417 - val_loss: 0.3048 - val_accuracy: 0.8452\n",
      "Epoch 256/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3245 - accuracy: 0.8375 - val_loss: 0.3027 - val_accuracy: 0.8357\n",
      "Epoch 257/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3235 - accuracy: 0.8387 - val_loss: 0.3029 - val_accuracy: 0.8429\n",
      "Epoch 258/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3233 - accuracy: 0.8363 - val_loss: 0.3031 - val_accuracy: 0.8405\n",
      "Epoch 259/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3252 - accuracy: 0.8375 - val_loss: 0.3085 - val_accuracy: 0.8333\n",
      "Epoch 260/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3243 - accuracy: 0.8381 - val_loss: 0.3063 - val_accuracy: 0.8452\n",
      "Epoch 261/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3250 - accuracy: 0.8417 - val_loss: 0.3021 - val_accuracy: 0.8357\n",
      "Epoch 262/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3245 - accuracy: 0.8369 - val_loss: 0.3044 - val_accuracy: 0.8452\n",
      "Epoch 263/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3255 - accuracy: 0.8375 - val_loss: 0.3063 - val_accuracy: 0.8262\n",
      "Epoch 264/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3233 - accuracy: 0.8363 - val_loss: 0.3044 - val_accuracy: 0.8310\n",
      "Epoch 265/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3238 - accuracy: 0.8458 - val_loss: 0.3062 - val_accuracy: 0.8405\n",
      "Epoch 266/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3242 - accuracy: 0.8435 - val_loss: 0.3057 - val_accuracy: 0.8357\n",
      "Epoch 267/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3260 - accuracy: 0.8417 - val_loss: 0.3070 - val_accuracy: 0.8262\n",
      "Epoch 268/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3305 - accuracy: 0.8351 - val_loss: 0.3072 - val_accuracy: 0.8333\n",
      "Epoch 269/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3268 - accuracy: 0.8351 - val_loss: 0.3051 - val_accuracy: 0.8381\n",
      "Epoch 270/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3253 - accuracy: 0.8351 - val_loss: 0.3080 - val_accuracy: 0.8405\n",
      "Epoch 271/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3252 - accuracy: 0.8292 - val_loss: 0.3062 - val_accuracy: 0.8405\n",
      "Epoch 272/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3241 - accuracy: 0.8423 - val_loss: 0.3039 - val_accuracy: 0.8405\n",
      "Epoch 273/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3264 - accuracy: 0.8369 - val_loss: 0.3064 - val_accuracy: 0.8429\n",
      "Epoch 274/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3246 - accuracy: 0.8423 - val_loss: 0.3034 - val_accuracy: 0.8429\n",
      "Epoch 275/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3246 - accuracy: 0.8375 - val_loss: 0.3081 - val_accuracy: 0.8357\n",
      "Epoch 276/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3290 - accuracy: 0.8387 - val_loss: 0.3095 - val_accuracy: 0.8476\n",
      "Epoch 277/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3257 - accuracy: 0.8429 - val_loss: 0.3038 - val_accuracy: 0.8333\n",
      "Epoch 278/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3238 - accuracy: 0.8393 - val_loss: 0.3084 - val_accuracy: 0.8333\n",
      "Epoch 279/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3241 - accuracy: 0.8369 - val_loss: 0.3059 - val_accuracy: 0.8405\n",
      "Epoch 280/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3278 - accuracy: 0.8286 - val_loss: 0.3273 - val_accuracy: 0.8333\n",
      "Epoch 281/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3304 - accuracy: 0.8363 - val_loss: 0.3060 - val_accuracy: 0.8310\n",
      "Epoch 282/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3268 - accuracy: 0.8357 - val_loss: 0.3095 - val_accuracy: 0.8381\n",
      "Epoch 283/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3243 - accuracy: 0.8363 - val_loss: 0.3075 - val_accuracy: 0.8405\n",
      "Epoch 284/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3252 - accuracy: 0.8310 - val_loss: 0.3025 - val_accuracy: 0.8381\n",
      "Epoch 285/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3241 - accuracy: 0.8387 - val_loss: 0.3060 - val_accuracy: 0.8381\n",
      "Epoch 286/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3236 - accuracy: 0.8429 - val_loss: 0.3063 - val_accuracy: 0.8333\n",
      "Epoch 287/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3242 - accuracy: 0.8399 - val_loss: 0.3055 - val_accuracy: 0.8310\n",
      "Epoch 288/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3232 - accuracy: 0.8446 - val_loss: 0.3050 - val_accuracy: 0.8238\n",
      "Epoch 289/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3223 - accuracy: 0.8452 - val_loss: 0.3052 - val_accuracy: 0.8333\n",
      "Epoch 290/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3231 - accuracy: 0.8440 - val_loss: 0.3034 - val_accuracy: 0.8405\n",
      "Epoch 291/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3230 - accuracy: 0.8429 - val_loss: 0.3019 - val_accuracy: 0.8429\n",
      "Epoch 292/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3223 - accuracy: 0.8423 - val_loss: 0.3041 - val_accuracy: 0.8429\n",
      "Epoch 293/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3224 - accuracy: 0.8452 - val_loss: 0.3051 - val_accuracy: 0.8357\n",
      "Epoch 294/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3218 - accuracy: 0.8452 - val_loss: 0.3039 - val_accuracy: 0.8381\n",
      "Epoch 295/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3237 - accuracy: 0.8357 - val_loss: 0.3058 - val_accuracy: 0.8381\n",
      "Epoch 296/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3256 - accuracy: 0.8399 - val_loss: 0.3055 - val_accuracy: 0.8452\n",
      "Epoch 297/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3254 - accuracy: 0.8381 - val_loss: 0.3037 - val_accuracy: 0.8262\n",
      "Epoch 298/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3235 - accuracy: 0.8405 - val_loss: 0.3041 - val_accuracy: 0.8286\n",
      "Epoch 299/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3232 - accuracy: 0.8470 - val_loss: 0.3029 - val_accuracy: 0.8381\n",
      "Epoch 300/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3247 - accuracy: 0.8411 - val_loss: 0.3051 - val_accuracy: 0.8333\n",
      "Epoch 301/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3229 - accuracy: 0.8399 - val_loss: 0.3040 - val_accuracy: 0.8333\n",
      "Epoch 302/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3241 - accuracy: 0.8411 - val_loss: 0.3037 - val_accuracy: 0.8405\n",
      "Epoch 303/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3228 - accuracy: 0.8440 - val_loss: 0.3054 - val_accuracy: 0.8333\n",
      "Epoch 304/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3242 - accuracy: 0.8393 - val_loss: 0.3035 - val_accuracy: 0.8381\n",
      "Epoch 305/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3213 - accuracy: 0.8464 - val_loss: 0.3048 - val_accuracy: 0.8286\n",
      "Epoch 306/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3233 - accuracy: 0.8405 - val_loss: 0.3045 - val_accuracy: 0.8310\n",
      "Epoch 307/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3244 - accuracy: 0.8452 - val_loss: 0.3062 - val_accuracy: 0.8381\n",
      "Epoch 308/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3264 - accuracy: 0.8435 - val_loss: 0.3082 - val_accuracy: 0.8286\n",
      "Epoch 309/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3237 - accuracy: 0.8393 - val_loss: 0.3041 - val_accuracy: 0.8429\n",
      "Epoch 310/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3225 - accuracy: 0.8411 - val_loss: 0.3038 - val_accuracy: 0.8429\n",
      "Epoch 311/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3227 - accuracy: 0.8429 - val_loss: 0.3043 - val_accuracy: 0.8286\n",
      "Epoch 312/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3219 - accuracy: 0.8429 - val_loss: 0.3042 - val_accuracy: 0.8310\n",
      "Epoch 313/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3225 - accuracy: 0.8429 - val_loss: 0.3028 - val_accuracy: 0.8452\n",
      "Epoch 314/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3217 - accuracy: 0.8440 - val_loss: 0.3041 - val_accuracy: 0.8405\n",
      "Epoch 315/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3282 - accuracy: 0.8357 - val_loss: 0.3060 - val_accuracy: 0.8333\n",
      "Epoch 316/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3246 - accuracy: 0.8369 - val_loss: 0.3049 - val_accuracy: 0.8500\n",
      "Epoch 317/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3229 - accuracy: 0.8357 - val_loss: 0.3039 - val_accuracy: 0.8405\n",
      "Epoch 318/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3244 - accuracy: 0.8357 - val_loss: 0.3107 - val_accuracy: 0.8452\n",
      "Epoch 319/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3225 - accuracy: 0.8363 - val_loss: 0.3041 - val_accuracy: 0.8476\n",
      "Epoch 320/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3223 - accuracy: 0.8429 - val_loss: 0.3059 - val_accuracy: 0.8310\n",
      "Epoch 321/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3223 - accuracy: 0.8363 - val_loss: 0.3032 - val_accuracy: 0.8405\n",
      "Epoch 322/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3227 - accuracy: 0.8393 - val_loss: 0.3026 - val_accuracy: 0.8405\n",
      "Epoch 323/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3220 - accuracy: 0.8369 - val_loss: 0.3058 - val_accuracy: 0.8357\n",
      "Epoch 324/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3226 - accuracy: 0.8393 - val_loss: 0.3059 - val_accuracy: 0.8286\n",
      "Epoch 325/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3230 - accuracy: 0.8399 - val_loss: 0.3050 - val_accuracy: 0.8310\n",
      "Epoch 326/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3225 - accuracy: 0.8399 - val_loss: 0.3027 - val_accuracy: 0.8381\n",
      "Epoch 327/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3221 - accuracy: 0.8393 - val_loss: 0.3078 - val_accuracy: 0.8452\n",
      "Epoch 328/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3224 - accuracy: 0.8375 - val_loss: 0.3053 - val_accuracy: 0.8405\n",
      "Epoch 329/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3225 - accuracy: 0.8423 - val_loss: 0.3053 - val_accuracy: 0.8429\n",
      "Epoch 330/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3217 - accuracy: 0.8446 - val_loss: 0.3027 - val_accuracy: 0.8476\n",
      "Epoch 331/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3224 - accuracy: 0.8440 - val_loss: 0.3033 - val_accuracy: 0.8476\n",
      "Epoch 332/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3237 - accuracy: 0.8470 - val_loss: 0.3166 - val_accuracy: 0.8429\n",
      "Epoch 333/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3303 - accuracy: 0.8405 - val_loss: 0.3039 - val_accuracy: 0.8405\n",
      "Epoch 334/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3222 - accuracy: 0.8387 - val_loss: 0.3055 - val_accuracy: 0.8286\n",
      "Epoch 335/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3222 - accuracy: 0.8393 - val_loss: 0.3039 - val_accuracy: 0.8429\n",
      "Epoch 336/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3227 - accuracy: 0.8345 - val_loss: 0.3034 - val_accuracy: 0.8286\n",
      "Epoch 337/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3219 - accuracy: 0.8470 - val_loss: 0.3031 - val_accuracy: 0.8429\n",
      "Epoch 338/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3218 - accuracy: 0.8482 - val_loss: 0.3026 - val_accuracy: 0.8357\n",
      "Epoch 339/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3231 - accuracy: 0.8452 - val_loss: 0.3029 - val_accuracy: 0.8429\n",
      "Epoch 340/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3215 - accuracy: 0.8452 - val_loss: 0.3054 - val_accuracy: 0.8381\n",
      "Epoch 341/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3229 - accuracy: 0.8411 - val_loss: 0.3034 - val_accuracy: 0.8405\n",
      "Epoch 342/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3220 - accuracy: 0.8339 - val_loss: 0.3028 - val_accuracy: 0.8381\n",
      "Epoch 343/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3221 - accuracy: 0.8423 - val_loss: 0.3041 - val_accuracy: 0.8405\n",
      "Epoch 344/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3225 - accuracy: 0.8429 - val_loss: 0.3033 - val_accuracy: 0.8381\n",
      "Epoch 345/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3225 - accuracy: 0.8405 - val_loss: 0.3028 - val_accuracy: 0.8429\n",
      "Epoch 346/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3213 - accuracy: 0.8464 - val_loss: 0.3051 - val_accuracy: 0.8333\n",
      "Epoch 347/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3285 - accuracy: 0.8315 - val_loss: 0.3041 - val_accuracy: 0.8405\n",
      "Epoch 348/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3209 - accuracy: 0.8440 - val_loss: 0.3029 - val_accuracy: 0.8286\n",
      "Epoch 349/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3223 - accuracy: 0.8470 - val_loss: 0.3055 - val_accuracy: 0.8452\n",
      "Epoch 350/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3219 - accuracy: 0.8393 - val_loss: 0.3033 - val_accuracy: 0.8476\n",
      "Epoch 351/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3388 - accuracy: 0.8375 - val_loss: 0.3037 - val_accuracy: 0.8262\n",
      "Epoch 352/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3235 - accuracy: 0.8429 - val_loss: 0.3026 - val_accuracy: 0.8429\n",
      "Epoch 353/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3230 - accuracy: 0.8435 - val_loss: 0.3055 - val_accuracy: 0.8262\n",
      "Epoch 354/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3220 - accuracy: 0.8399 - val_loss: 0.3032 - val_accuracy: 0.8357\n",
      "Epoch 355/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3232 - accuracy: 0.8399 - val_loss: 0.3042 - val_accuracy: 0.8381\n",
      "Epoch 356/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3246 - accuracy: 0.8411 - val_loss: 0.3028 - val_accuracy: 0.8310\n",
      "Epoch 357/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3222 - accuracy: 0.8399 - val_loss: 0.3038 - val_accuracy: 0.8357\n",
      "Epoch 358/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3227 - accuracy: 0.8369 - val_loss: 0.3043 - val_accuracy: 0.8333\n",
      "Epoch 359/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3226 - accuracy: 0.8417 - val_loss: 0.3025 - val_accuracy: 0.8429\n",
      "Epoch 360/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3208 - accuracy: 0.8399 - val_loss: 0.3037 - val_accuracy: 0.8310\n",
      "Epoch 361/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3220 - accuracy: 0.8417 - val_loss: 0.3052 - val_accuracy: 0.8500\n",
      "Epoch 362/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3225 - accuracy: 0.8417 - val_loss: 0.3050 - val_accuracy: 0.8381\n",
      "Epoch 363/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3284 - accuracy: 0.8393 - val_loss: 0.3082 - val_accuracy: 0.8190\n",
      "Epoch 364/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3247 - accuracy: 0.8405 - val_loss: 0.3081 - val_accuracy: 0.8405\n",
      "Epoch 365/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3227 - accuracy: 0.8452 - val_loss: 0.3017 - val_accuracy: 0.8452\n",
      "Epoch 366/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3230 - accuracy: 0.8452 - val_loss: 0.3029 - val_accuracy: 0.8429\n",
      "Epoch 367/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3212 - accuracy: 0.8423 - val_loss: 0.3039 - val_accuracy: 0.8452\n",
      "Epoch 368/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3211 - accuracy: 0.8417 - val_loss: 0.3017 - val_accuracy: 0.8452\n",
      "Epoch 369/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3210 - accuracy: 0.8458 - val_loss: 0.3000 - val_accuracy: 0.8452\n",
      "Epoch 370/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3220 - accuracy: 0.8440 - val_loss: 0.3021 - val_accuracy: 0.8476\n",
      "Epoch 371/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3202 - accuracy: 0.8458 - val_loss: 0.3035 - val_accuracy: 0.8452\n",
      "Epoch 372/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3209 - accuracy: 0.8482 - val_loss: 0.3023 - val_accuracy: 0.8429\n",
      "Epoch 373/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3217 - accuracy: 0.8417 - val_loss: 0.3028 - val_accuracy: 0.8476\n",
      "Epoch 374/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3213 - accuracy: 0.8440 - val_loss: 0.3029 - val_accuracy: 0.8381\n",
      "Epoch 375/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3214 - accuracy: 0.8452 - val_loss: 0.3042 - val_accuracy: 0.8357\n",
      "Epoch 376/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3208 - accuracy: 0.8482 - val_loss: 0.3037 - val_accuracy: 0.8381\n",
      "Epoch 377/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3211 - accuracy: 0.8440 - val_loss: 0.3030 - val_accuracy: 0.8310\n",
      "Epoch 378/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3219 - accuracy: 0.8417 - val_loss: 0.3030 - val_accuracy: 0.8405\n",
      "Epoch 379/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3207 - accuracy: 0.8405 - val_loss: 0.3016 - val_accuracy: 0.8381\n",
      "Epoch 380/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3250 - accuracy: 0.8315 - val_loss: 0.3050 - val_accuracy: 0.8381\n",
      "Epoch 381/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3262 - accuracy: 0.8405 - val_loss: 0.3029 - val_accuracy: 0.8452\n",
      "Epoch 382/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3229 - accuracy: 0.8452 - val_loss: 0.3080 - val_accuracy: 0.8500\n",
      "Epoch 383/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3234 - accuracy: 0.8357 - val_loss: 0.3048 - val_accuracy: 0.8381\n",
      "Epoch 384/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3231 - accuracy: 0.8429 - val_loss: 0.3047 - val_accuracy: 0.8452\n",
      "Epoch 385/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3222 - accuracy: 0.8464 - val_loss: 0.3032 - val_accuracy: 0.8333\n",
      "Epoch 386/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3209 - accuracy: 0.8393 - val_loss: 0.3028 - val_accuracy: 0.8429\n",
      "Epoch 387/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3210 - accuracy: 0.8417 - val_loss: 0.3032 - val_accuracy: 0.8357\n",
      "Epoch 388/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3233 - accuracy: 0.8381 - val_loss: 0.3047 - val_accuracy: 0.8452\n",
      "Epoch 389/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3218 - accuracy: 0.8417 - val_loss: 0.3043 - val_accuracy: 0.8429\n",
      "Epoch 390/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3222 - accuracy: 0.8399 - val_loss: 0.3018 - val_accuracy: 0.8500\n",
      "Epoch 391/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3220 - accuracy: 0.8399 - val_loss: 0.3045 - val_accuracy: 0.8452\n",
      "Epoch 392/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3215 - accuracy: 0.8464 - val_loss: 0.3049 - val_accuracy: 0.8381\n",
      "Epoch 393/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3204 - accuracy: 0.8464 - val_loss: 0.3029 - val_accuracy: 0.8429\n",
      "Epoch 394/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3203 - accuracy: 0.8458 - val_loss: 0.3008 - val_accuracy: 0.8452\n",
      "Epoch 395/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3208 - accuracy: 0.8452 - val_loss: 0.3024 - val_accuracy: 0.8476\n",
      "Epoch 396/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3212 - accuracy: 0.8458 - val_loss: 0.3039 - val_accuracy: 0.8333\n",
      "Epoch 397/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3232 - accuracy: 0.8417 - val_loss: 0.3043 - val_accuracy: 0.8262\n",
      "Epoch 398/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3268 - accuracy: 0.8387 - val_loss: 0.3022 - val_accuracy: 0.8333\n",
      "Epoch 399/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3224 - accuracy: 0.8423 - val_loss: 0.3051 - val_accuracy: 0.8405\n",
      "Epoch 400/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3232 - accuracy: 0.8393 - val_loss: 0.3060 - val_accuracy: 0.8476\n",
      "Epoch 401/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3217 - accuracy: 0.8393 - val_loss: 0.3011 - val_accuracy: 0.8452\n",
      "Epoch 402/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3212 - accuracy: 0.8482 - val_loss: 0.3063 - val_accuracy: 0.8333\n",
      "Epoch 403/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3217 - accuracy: 0.8476 - val_loss: 0.3047 - val_accuracy: 0.8429\n",
      "Epoch 404/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3217 - accuracy: 0.8411 - val_loss: 0.3055 - val_accuracy: 0.8452\n",
      "Epoch 405/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3216 - accuracy: 0.8387 - val_loss: 0.3019 - val_accuracy: 0.8429\n",
      "Epoch 406/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3222 - accuracy: 0.8488 - val_loss: 0.3040 - val_accuracy: 0.8429\n",
      "Epoch 407/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3222 - accuracy: 0.8393 - val_loss: 0.3054 - val_accuracy: 0.8381\n",
      "Epoch 408/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3215 - accuracy: 0.8488 - val_loss: 0.3030 - val_accuracy: 0.8405\n",
      "Epoch 409/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3213 - accuracy: 0.8429 - val_loss: 0.3012 - val_accuracy: 0.8500\n",
      "Epoch 410/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3213 - accuracy: 0.8417 - val_loss: 0.3031 - val_accuracy: 0.8500\n",
      "Epoch 411/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3218 - accuracy: 0.8440 - val_loss: 0.3044 - val_accuracy: 0.8476\n",
      "Epoch 412/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3214 - accuracy: 0.8429 - val_loss: 0.3045 - val_accuracy: 0.8333\n",
      "Epoch 413/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3200 - accuracy: 0.8464 - val_loss: 0.3045 - val_accuracy: 0.8381\n",
      "Epoch 414/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3212 - accuracy: 0.8423 - val_loss: 0.3049 - val_accuracy: 0.8357\n",
      "Epoch 415/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3215 - accuracy: 0.8429 - val_loss: 0.3020 - val_accuracy: 0.8333\n",
      "Epoch 416/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3213 - accuracy: 0.8435 - val_loss: 0.3046 - val_accuracy: 0.8286\n",
      "Epoch 417/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3203 - accuracy: 0.8452 - val_loss: 0.3029 - val_accuracy: 0.8429\n",
      "Epoch 418/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3223 - accuracy: 0.8435 - val_loss: 0.3011 - val_accuracy: 0.8357\n",
      "Epoch 419/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3219 - accuracy: 0.8440 - val_loss: 0.3047 - val_accuracy: 0.8405\n",
      "Epoch 420/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3214 - accuracy: 0.8435 - val_loss: 0.3063 - val_accuracy: 0.8405\n",
      "Epoch 421/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3247 - accuracy: 0.8435 - val_loss: 0.3031 - val_accuracy: 0.8357\n",
      "Epoch 422/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3359 - accuracy: 0.8298 - val_loss: 0.3109 - val_accuracy: 0.8381\n",
      "Epoch 423/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3241 - accuracy: 0.8429 - val_loss: 0.3030 - val_accuracy: 0.8333\n",
      "Epoch 424/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3237 - accuracy: 0.8440 - val_loss: 0.3015 - val_accuracy: 0.8357\n",
      "Epoch 425/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3219 - accuracy: 0.8387 - val_loss: 0.3026 - val_accuracy: 0.8310\n",
      "Epoch 426/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3221 - accuracy: 0.8440 - val_loss: 0.3037 - val_accuracy: 0.8333\n",
      "Epoch 427/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3215 - accuracy: 0.8494 - val_loss: 0.3014 - val_accuracy: 0.8405\n",
      "Epoch 428/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3215 - accuracy: 0.8393 - val_loss: 0.3030 - val_accuracy: 0.8357\n",
      "Epoch 429/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3222 - accuracy: 0.8429 - val_loss: 0.3027 - val_accuracy: 0.8429\n",
      "Epoch 430/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3212 - accuracy: 0.8435 - val_loss: 0.3032 - val_accuracy: 0.8429\n",
      "Epoch 431/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3224 - accuracy: 0.8417 - val_loss: 0.3032 - val_accuracy: 0.8452\n",
      "Epoch 432/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3205 - accuracy: 0.8476 - val_loss: 0.3021 - val_accuracy: 0.8429\n",
      "Epoch 433/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3206 - accuracy: 0.8393 - val_loss: 0.3015 - val_accuracy: 0.8500\n",
      "Epoch 434/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3204 - accuracy: 0.8458 - val_loss: 0.3027 - val_accuracy: 0.8476\n",
      "Epoch 435/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3201 - accuracy: 0.8476 - val_loss: 0.3039 - val_accuracy: 0.8429\n",
      "Epoch 436/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3205 - accuracy: 0.8482 - val_loss: 0.3023 - val_accuracy: 0.8357\n",
      "Epoch 437/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3209 - accuracy: 0.8411 - val_loss: 0.3005 - val_accuracy: 0.8429\n",
      "Epoch 438/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3207 - accuracy: 0.8488 - val_loss: 0.3019 - val_accuracy: 0.8405\n",
      "Epoch 439/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3200 - accuracy: 0.8470 - val_loss: 0.3041 - val_accuracy: 0.8405\n",
      "Epoch 440/500\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.3214 - accuracy: 0.8446 - val_loss: 0.3021 - val_accuracy: 0.8405\n",
      "Epoch 441/500\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.3213 - accuracy: 0.8363 - val_loss: 0.3039 - val_accuracy: 0.8357\n",
      "Epoch 442/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3197 - accuracy: 0.8464 - val_loss: 0.3035 - val_accuracy: 0.8357\n",
      "Epoch 443/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3199 - accuracy: 0.8446 - val_loss: 0.3022 - val_accuracy: 0.8476\n",
      "Epoch 444/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3210 - accuracy: 0.8446 - val_loss: 0.3027 - val_accuracy: 0.8381\n",
      "Epoch 445/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3203 - accuracy: 0.8393 - val_loss: 0.3021 - val_accuracy: 0.8429\n",
      "Epoch 446/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3210 - accuracy: 0.8417 - val_loss: 0.3020 - val_accuracy: 0.8429\n",
      "Epoch 447/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3214 - accuracy: 0.8440 - val_loss: 0.3045 - val_accuracy: 0.8429\n",
      "Epoch 448/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3209 - accuracy: 0.8429 - val_loss: 0.3031 - val_accuracy: 0.8429\n",
      "Epoch 449/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3210 - accuracy: 0.8470 - val_loss: 0.3035 - val_accuracy: 0.8476\n",
      "Epoch 450/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3215 - accuracy: 0.8375 - val_loss: 0.3028 - val_accuracy: 0.8381\n",
      "Epoch 451/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3203 - accuracy: 0.8405 - val_loss: 0.3048 - val_accuracy: 0.8429\n",
      "Epoch 452/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3207 - accuracy: 0.8446 - val_loss: 0.3021 - val_accuracy: 0.8429\n",
      "Epoch 453/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3211 - accuracy: 0.8417 - val_loss: 0.3055 - val_accuracy: 0.8405\n",
      "Epoch 454/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3209 - accuracy: 0.8423 - val_loss: 0.3038 - val_accuracy: 0.8310\n",
      "Epoch 455/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3207 - accuracy: 0.8446 - val_loss: 0.3023 - val_accuracy: 0.8429\n",
      "Epoch 456/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3206 - accuracy: 0.8488 - val_loss: 0.3016 - val_accuracy: 0.8452\n",
      "Epoch 457/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3209 - accuracy: 0.8435 - val_loss: 0.3028 - val_accuracy: 0.8381\n",
      "Epoch 458/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3213 - accuracy: 0.8464 - val_loss: 0.3023 - val_accuracy: 0.8357\n",
      "Epoch 459/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3196 - accuracy: 0.8429 - val_loss: 0.3033 - val_accuracy: 0.8405\n",
      "Epoch 460/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3207 - accuracy: 0.8446 - val_loss: 0.3050 - val_accuracy: 0.8452\n",
      "Epoch 461/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3229 - accuracy: 0.8417 - val_loss: 0.3031 - val_accuracy: 0.8452\n",
      "Epoch 462/500\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3235 - accuracy: 0.8452 - val_loss: 0.3047 - val_accuracy: 0.8500\n",
      "Epoch 463/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3210 - accuracy: 0.8405 - val_loss: 0.3015 - val_accuracy: 0.8429\n",
      "Epoch 464/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3210 - accuracy: 0.8464 - val_loss: 0.3034 - val_accuracy: 0.8405\n",
      "Epoch 465/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3210 - accuracy: 0.8405 - val_loss: 0.3036 - val_accuracy: 0.8429\n",
      "Epoch 466/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3215 - accuracy: 0.8417 - val_loss: 0.3034 - val_accuracy: 0.8333\n",
      "Epoch 467/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3213 - accuracy: 0.8464 - val_loss: 0.3046 - val_accuracy: 0.8286\n",
      "Epoch 468/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3207 - accuracy: 0.8393 - val_loss: 0.3020 - val_accuracy: 0.8405\n",
      "Epoch 469/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3216 - accuracy: 0.8470 - val_loss: 0.3072 - val_accuracy: 0.8333\n",
      "Epoch 470/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3222 - accuracy: 0.8435 - val_loss: 0.3025 - val_accuracy: 0.8405\n",
      "Epoch 471/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3211 - accuracy: 0.8446 - val_loss: 0.3046 - val_accuracy: 0.8286\n",
      "Epoch 472/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3215 - accuracy: 0.8482 - val_loss: 0.3056 - val_accuracy: 0.8500\n",
      "Epoch 473/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3206 - accuracy: 0.8452 - val_loss: 0.3044 - val_accuracy: 0.8476\n",
      "Epoch 474/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3205 - accuracy: 0.8548 - val_loss: 0.3031 - val_accuracy: 0.8476\n",
      "Epoch 475/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3204 - accuracy: 0.8429 - val_loss: 0.3040 - val_accuracy: 0.8405\n",
      "Epoch 476/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3199 - accuracy: 0.8435 - val_loss: 0.3014 - val_accuracy: 0.8357\n",
      "Epoch 477/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3214 - accuracy: 0.8381 - val_loss: 0.3047 - val_accuracy: 0.8381\n",
      "Epoch 478/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3225 - accuracy: 0.8411 - val_loss: 0.3030 - val_accuracy: 0.8476\n",
      "Epoch 479/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3197 - accuracy: 0.8452 - val_loss: 0.3003 - val_accuracy: 0.8381\n",
      "Epoch 480/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3214 - accuracy: 0.8399 - val_loss: 0.3026 - val_accuracy: 0.8381\n",
      "Epoch 481/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3209 - accuracy: 0.8375 - val_loss: 0.3014 - val_accuracy: 0.8429\n",
      "Epoch 482/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3214 - accuracy: 0.8464 - val_loss: 0.3033 - val_accuracy: 0.8381\n",
      "Epoch 483/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3200 - accuracy: 0.8446 - val_loss: 0.3032 - val_accuracy: 0.8286\n",
      "Epoch 484/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3208 - accuracy: 0.8411 - val_loss: 0.3031 - val_accuracy: 0.8381\n",
      "Epoch 485/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3204 - accuracy: 0.8429 - val_loss: 0.3022 - val_accuracy: 0.8429\n",
      "Epoch 486/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3190 - accuracy: 0.8470 - val_loss: 0.3021 - val_accuracy: 0.8452\n",
      "Epoch 487/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3204 - accuracy: 0.8423 - val_loss: 0.3057 - val_accuracy: 0.8381\n",
      "Epoch 488/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3203 - accuracy: 0.8429 - val_loss: 0.3023 - val_accuracy: 0.8500\n",
      "Epoch 489/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3219 - accuracy: 0.8435 - val_loss: 0.3040 - val_accuracy: 0.8452\n",
      "Epoch 490/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3202 - accuracy: 0.8464 - val_loss: 0.3033 - val_accuracy: 0.8476\n",
      "Epoch 491/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3199 - accuracy: 0.8411 - val_loss: 0.3035 - val_accuracy: 0.8381\n",
      "Epoch 492/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3195 - accuracy: 0.8494 - val_loss: 0.3024 - val_accuracy: 0.8500\n",
      "Epoch 493/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3198 - accuracy: 0.8512 - val_loss: 0.3017 - val_accuracy: 0.8476\n",
      "Epoch 494/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3200 - accuracy: 0.8417 - val_loss: 0.3012 - val_accuracy: 0.8429\n",
      "Epoch 495/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3206 - accuracy: 0.8423 - val_loss: 0.3015 - val_accuracy: 0.8452\n",
      "Epoch 496/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3207 - accuracy: 0.8429 - val_loss: 0.3026 - val_accuracy: 0.8452\n",
      "Epoch 497/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3204 - accuracy: 0.8536 - val_loss: 0.3017 - val_accuracy: 0.8429\n",
      "Epoch 498/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3199 - accuracy: 0.8458 - val_loss: 0.3027 - val_accuracy: 0.8429\n",
      "Epoch 499/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3212 - accuracy: 0.8440 - val_loss: 0.3045 - val_accuracy: 0.8429\n",
      "Epoch 500/500\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3195 - accuracy: 0.8476 - val_loss: 0.3020 - val_accuracy: 0.8429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x183f802d450>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Machine Learning - Train the model\n",
    "\n",
    "model.fit(X_train, Y_train, epochs = 500, batch_size = 21, validation_data = (X_test, Y_test), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3020 - accuracy: 0.8429\n",
      "Mean Squared Error:  [0.3019743263721466, 0.8428571224212646]\n"
     ]
    }
   ],
   "source": [
    "# Machine Learning - Evaluate the model\n",
    "\n",
    "mse = model.evaluate(X_test, Y_test, verbose = 1)\n",
    "print(\"Mean Squared Error: \", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from the file\n",
    "test = pd.read_csv('myDataTest.csv', header = None)\n",
    "\n",
    "test.head()\n",
    "\n",
    "Dataset_Test = test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.40000000e+00 1.20000000e+00 0.00000000e+00 9.86345831e-05\n",
      " 1.70002796e-04 2.94991801e-04 3.13640718e-04 2.97603998e-04\n",
      " 0.00000000e+00 5.55601964e-05 1.39332949e-04 0.00000000e+00\n",
      " 0.00000000e+00 6.04454379e-05 0.00000000e+00 1.00778973e-04\n",
      " 3.09492753e-04 3.23612642e-04 5.14996786e-04 6.03883842e-04\n",
      " 1.13682937e-05 2.52433233e-04 4.28608160e-04 0.00000000e+00\n",
      " 0.00000000e+00 1.98822566e-04 0.00000000e+00 3.43138436e-06\n",
      " 6.99308787e-05 2.37714863e-04 2.14060363e-04 2.01804856e-04\n",
      " 4.86203643e-05 1.26126492e-04 1.53103209e-04 0.00000000e+00\n",
      " 0.00000000e+00 4.29760888e-05 0.00000000e+00 1.83330034e-05\n",
      " 4.95439167e-05 2.17652332e-04 1.49906719e-04 1.22716308e-04\n",
      " 2.19563547e-06 4.25320924e-05 6.52372748e-05 0.00000000e+00\n",
      " 0.00000000e+00 1.47314730e-05]\n"
     ]
    }
   ],
   "source": [
    "starting_X = 3.0;\n",
    "starting_Y = 0.0;\n",
    "arr = np.zeros((1, 0));\n",
    "X_test_2 = np.empty(30, dtype = object);\n",
    "Y_test_2 = np.empty(30, dtype = object);\n",
    "\n",
    "new_arr_test = np.empty((30, 50));\n",
    "\n",
    "for i in range(0, 29):\n",
    "    if i <= 5:\n",
    "        true_X = starting_X - i*0.6;\n",
    "        true_Y = starting_Y;\n",
    "    elif i <= 10:\n",
    "        true_X = 0.0 + (i-5)*0.6;\n",
    "        true_Y = starting_Y + 0.6;\n",
    "    elif i <= 15:\n",
    "        true_X = starting_X - (i-10)*0.6;\n",
    "        true_Y = starting_Y + 1.2;\n",
    "    elif i <= 20:\n",
    "        true_X = 0.0 + (i-15)*0.6;\n",
    "        true_Y = starting_Y + 1.8;\n",
    "    elif i <= 25:\n",
    "        true_X = starting_X - (i-20)*0.6;\n",
    "        true_Y = starting_Y + 2.4;\n",
    "    elif i <= 30:\n",
    "        true_X = 0.0 + (i-25)*0.6;\n",
    "        true_Y = starting_Y + 3.0;\n",
    "\n",
    "        \n",
    "    new_arr_test[i,:] = np.array([true_X, true_Y, Dataset_Test[i, 0], Dataset_Test[i, 1], Dataset_Test[i, 2], Dataset_Test[i, 3], Dataset_Test[i, 4], Dataset_Test[i, 5], Dataset_Test[i, 6], Dataset_Test[i, 7], Dataset_Test[i, 8], Dataset_Test[i, 9], Dataset_Test[i, 10], Dataset_Test[i, 11], Dataset_Test[i, 12], Dataset_Test[i, 13], Dataset_Test[i, 14], Dataset_Test[i, 15], Dataset_Test[i, 16], Dataset_Test[i, 17], Dataset_Test[i, 18], Dataset_Test[i, 19], Dataset_Test[i, 20], Dataset_Test[i, 21], Dataset_Test[i, 22], Dataset_Test[i, 23], Dataset_Test[i, 24], Dataset_Test[i, 25], Dataset_Test[i, 26], Dataset_Test[i, 27], Dataset_Test[i, 28], Dataset_Test[i, 29], Dataset_Test[i, 30], Dataset_Test[i, 31], Dataset_Test[i, 32], Dataset_Test[i, 33], Dataset_Test[i, 34], Dataset_Test[i, 35], Dataset_Test[i, 36], Dataset_Test[i, 37], Dataset_Test[i, 38], Dataset_Test[i, 39], Dataset_Test[i, 40], Dataset_Test[i, 41], Dataset_Test[i, 42], Dataset_Test[i, 43], Dataset_Test[i, 44], Dataset_Test[i, 45], Dataset_Test[i, 46], Dataset_Test[i, 47]])\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "print(new_arr_test[11,:])\n",
    "# print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "Mean squared error for test data:  0.4024733333333334\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Mean squared error for new data:  1.1573333333333333\n"
     ]
    }
   ],
   "source": [
    "# Machine Learning - Make predictions\n",
    "X_test_test = new_arr_test[:, 2:50];\n",
    "# X_test_test = scaler.transform(X_test_test)\n",
    "# X_for_test = X_test_test[1, :];\n",
    "Y_test_test = new_arr_test[:, 0:2];\n",
    "# Y_for_test = Y_test_test[1, :];\n",
    "\n",
    "\n",
    "y_old_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "y_pred_x = y_old_pred[:, 0]\n",
    "y_pred_y = y_old_pred[:, 1]\n",
    "\n",
    "# Round the predicted values to the nearest integer\n",
    "y_pred_x = np.rint(y_pred_x.flatten())\n",
    "y_pred_y = np.rint(y_pred_y.flatten())\n",
    "\n",
    "# Combine the predicted x and y values into a single array of (x, y) tuples\n",
    "y_pred = np.stack((y_pred_x, y_pred_y), axis=1)\n",
    "\n",
    "# Calculate accuracy score\n",
    "mse = metrics.mean_squared_error(Y_test, y_pred)\n",
    "print(\"Mean squared error for test data: \", mse)\n",
    "\n",
    "X_test_test = scaler.transform(X_test_test)\n",
    "\n",
    "\n",
    "y_old_pred = model.predict(X_test_test)\n",
    "\n",
    "y_pred_x = y_old_pred[:, 0]\n",
    "y_pred_y = y_old_pred[:, 1]\n",
    "\n",
    "# Round the predicted values to the nearest integer\n",
    "y_pred_x = np.rint(y_pred_x.flatten())\n",
    "y_pred_y = np.rint(y_pred_y.flatten())\n",
    "\n",
    "# Combine the predicted x and y values into a single array of (x, y) tuples\n",
    "y_pred = np.stack((y_pred_x, y_pred_y), axis=1)\n",
    "\n",
    "# Calculate accuracy score\n",
    "mse = metrics.mean_squared_error(Y_test_test, y_pred)\n",
    "print(\"Mean squared error for new data: \", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Assume you have a trained model called \"model\"\n",
    "# and a test set called X_test and y_test\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Create a scatter plot showing the real points in blue\n",
    "plt.scatter(Y_test[:,0], Y_test[:,1], color='blue', label='Real Points')\n",
    "\n",
    "x_pred = y_pred[:, 0]\n",
    "y_pred = y_pred[:, 1]\n",
    "\n",
    "# Create a scatter plot showing the predicted points in red\n",
    "plt.scatter(x_pred, y_pred, color='red', label='Predicted Points')\n",
    "\n",
    "# Loop through each point in the test set\n",
    "for i in range(20 , 25):\n",
    "    # Get the x and y coordinates for the real and predicted points\n",
    "    x_real, y_real = Y_test[i]\n",
    "    x_pred_arrow = x_pred[i]\n",
    "    y_pred_arrow = y_pred[i]\n",
    "    \n",
    "    # Add an arrow from the real point to the predicted point\n",
    "    plt.arrow(x_real, y_real, x_pred_arrow - x_real, y_pred_arrow - y_real, \n",
    "              length_includes_head=True, head_width=0.05, color='green')\n",
    "    \n",
    "# Set the x-axis label to \"X\"\n",
    "plt.xlabel('X')\n",
    "\n",
    "# Set the y-axis label to \"Y\"\n",
    "plt.ylabel('Y')\n",
    "\n",
    "# Set the title of the plot to \"Real vs Predicted Points\"\n",
    "plt.title('Real vs Predicted Points')\n",
    "\n",
    "# Add a legend to the plot\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eb59da0c20e2b97dd7886fd48856db350b509b8c7fcd926b16e2fee1316e5c32"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
